{
    "version": "1.0",
    "llm-defaults": {
        "model": "gpt-4",
        "temperature": 0.7,
        "max_tokens": 500
    },
    "llms": {
        "gpt-4": {
            "type": "openai"
        },
        "runpod-llama-3b": {
            "type": "vllm",
            "endpoint": "vllm-caiqtd1nirhws2",
            "max_tokens": 750,
            "temperature": 0.8
        }
    }
}
